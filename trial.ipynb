{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e8964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/lame/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ace2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract text and chunk using ‚Äî‚Äî separator\n",
    "def pdf_to_doc(pdf_path, document_name, document_type):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "\n",
    "    full_text = re.sub(r'[\\u2028\\u2029\\n\\r]+', ' ', full_text).strip()\n",
    "    sections = re.split(r'‚Äî‚Äî+', full_text)\n",
    "    sections = [sec.strip() for sec in sections if sec.strip()]\n",
    "\n",
    "    documents = []\n",
    "    for i, section in enumerate(sections):\n",
    "        documents.append(\n",
    "            Document(\n",
    "                page_content=section,\n",
    "                metadata={\n",
    "                    \"document_name\": document_name,\n",
    "                    \"document_type\": document_type,\n",
    "                    \"section_number\": i\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "091a5a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store documents in Chroma DB\n",
    "def store_in_chroma(pdf_path, document_name, document_type, persist_directory=\"./chroma_phi\"):\n",
    "    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
    "    data = vectordb.get()\n",
    "    existing = any(\n",
    "        metadata.get(\"document_name\") == document_name\n",
    "        for metadata in data['metadatas']\n",
    "    )\n",
    "    if existing:\n",
    "        print(f\"‚ö†Ô∏è Document with name '{document_name}' already exists. Use update_entries() to replace it.\")\n",
    "        return\n",
    "    docs = pdf_to_doc(pdf_path, document_name, document_type)\n",
    "    vectordb.add_documents(docs)\n",
    "    print(f\"‚úÖ Stored {len(docs)} chunks from '{document_name}' as '{document_type}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75bbbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_documents(persist_directory=\"./chroma_phi\"):\n",
    "    if not os.path.exists(persist_directory):\n",
    "        print(\"‚ö†Ô∏è No Chroma database found.\")\n",
    "        return\n",
    "\n",
    "    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
    "    data = vectordb.get()\n",
    "    seen = set()\n",
    "    if not data['documents']:\n",
    "        print(\"üì≠ No documents found in the vector store.\")\n",
    "        return\n",
    "\n",
    "    print(\"üìÑ Documents stored:\")\n",
    "    for metadata in data['metadatas']:\n",
    "        name = metadata.get(\"document_name\", \"Unknown\")\n",
    "        dtype = metadata.get(\"document_type\", \"Unknown\")\n",
    "        if (name, dtype) not in seen:\n",
    "            print(f\"‚Ä¢ Name: {name} | Type: {dtype}\")\n",
    "            seen.add((name, dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2930f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_database(persist_directory=\"./chroma_phi\"):\n",
    "    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
    "    \n",
    "    # Get all document IDs\n",
    "    data = vectordb.get()\n",
    "    all_ids = data.get('ids', [])\n",
    "\n",
    "    if not all_ids:\n",
    "        print(\"üì≠ Vector DB is already empty.\")\n",
    "        return\n",
    "\n",
    "    # Delete all documents\n",
    "    vectordb.delete(ids=all_ids)\n",
    "    print(f\"üßπ Cleared {len(all_ids)} documents from the vector DB at '{persist_directory}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bf5aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all entries by document name\n",
    "def delete_entries_by_name(document_name, persist_directory=\"./chroma_phi\"):\n",
    "    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
    "    data = vectordb.get()\n",
    "    matching_ids = [\n",
    "        doc_id for doc_id, metadata in zip(data['ids'], data['metadatas'])\n",
    "        if metadata.get(\"document_name\") == document_name\n",
    "    ]\n",
    "    if matching_ids:\n",
    "        vectordb.delete(ids=matching_ids)\n",
    "        print(f\"üßπ Deleted {len(matching_ids)} entries with document_name = '{document_name}'.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No entries found with document_name = '{document_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48b0a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update entries by re-uploading document\n",
    "def update_entries(pdf_path, document_name, document_type, persist_directory=\"./chroma_phi\"):\n",
    "    delete_entries_by_name(document_name, persist_directory)\n",
    "    store_in_chroma(pdf_path, document_name, document_type, persist_directory)\n",
    "    print(f\"üîÅ Updated entries for '{document_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "011704d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_document(document_name, persist_directory=\"./chroma_phi\"):\n",
    "    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
    "    docs = vectordb.get(where={\"document_name\": document_name})\n",
    "    chunks = docs['documents']\n",
    "    if not chunks:\n",
    "        print(f\"‚ùå No document found with name '{document_name}'.\")\n",
    "        return\n",
    "    print(f\"üìë Contents of '{document_name}':\\n\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"[Section {i+1}]\\n{chunk}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a235842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stored 15 chunks from 'Zoomie' as 'Project'.\n"
     ]
    }
   ],
   "source": [
    "store_in_chroma(\"/Users/diya/Desktop/projects pdf/Zoomie.pdf\", \"Zoomie\", \"Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8e0cda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No entries found with document_name = 'cookbook'.\n",
      "‚úÖ Stored 15 chunks from 'cookbook' as 'Project'.\n",
      "üîÅ Updated entries for 'cookbook'.\n"
     ]
    }
   ],
   "source": [
    "update_entries(\"/Users/diya/Desktop/projects pdf/cookbook.pdf\", \"cookbook\", \"Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5bcf928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìë Contents of 'Zoomie':\n",
      "\n",
      "[Section 1]\n",
      "Name of project: Zoomie\n",
      "--------------------------------------------------\n",
      "[Section 2]\n",
      "Introduction: Zoomie is an intelligent autonomous vehicle developed for low-cost field data  collection. Built on a Raspberry Pi 4 platform, the vehicle uses a camera for navigation and  object-distance detection via the YOLO algorithm. It drives autonomously toward a specified  location while avoiding obstacles. Once it reaches the destination, Zoomie begins recording the  surrounding audio. This audio is processed using speech-to-text conversion via Whisper, and the  transcribed content is then summarized using a transformer-based model. The final summary is  made available through a React-based frontend, allowing users to review information collected by  the vehicle without any direct intervention.\n",
      "--------------------------------------------------\n",
      "[Section 3]\n",
      "Summary: Zoomie is a compact autonomous vehicle powered by Raspberry Pi 4 that navigates to  a desired destination while detecting and avoiding obstacles using a real-time object-distance  detection system. Upon reaching the designated site, it activates a voice recorder, transcribes the  captured audio using speech-to-text, and generates a concise summary of the information. The  summarized text is then accessible through a connected React web application, enabling users to  monitor vehicle output remotely.\n",
      "--------------------------------------------------\n",
      "[Section 4]\n",
      "Project Type: Robotics, Autonomous Vehicle, AI Application\n",
      "--------------------------------------------------\n",
      "[Section 5]\n",
      "Date: December 2023\n",
      "--------------------------------------------------\n",
      "[Section 6]\n",
      "Fundamental Technologies / Tech Stack / Technologies Used: Python, OpenCV, YOLO,  Transformers, Whisper (for speech-to-text), React, Python, HuggingFace, Transformers (for text  summarization), Raspberry Pi 4 (hardware platform), Raspberry Pi Camera Module or USB  camera, Flask (for backend API serving summaries), NumPy (for image array manipulation),  PyTorch (for running YOLO and Whisper models), PyDub (for audio recording and preprocessing),  SpeechRecognition (optional interface for mic input), gTTS or pyttsx3 (optional fallback for TTS),  GPIO Zero (for controlling vehicle movement and sensors), Motor Driver (L298N H-Bridge),  Raspbian OS\n",
      "--------------------------------------------------\n",
      "[Section 7]\n",
      "Objectives: Develop a self-driving mini vehicle capable of reaching a specific location  autonomously; Implement real-time object detection and distance tracking to avoid obstacles;  Enable automated speech capture and transcription upon destination arrival; Generate a readable  summary of the transcribed text and make it available via a web interface.\n",
      "--------------------------------------------------\n",
      "[Section 8]\n",
      "Problem Statement: Autonomous vehicles are increasingly useful in tasks that require navigation  and information gathering in real-time. However, few small-scale, low-cost systems are equipped  with multimodal intelligence such as voice transcription and summarization at target locations.  Zoomie addresses this by combining navigation, perception, and language understanding into a  single, affordable system.\n",
      "--------------------------------------------------\n",
      "[Section 9]\n",
      "Methodology: The vehicle uses a mounted camera and YOLO for detecting objects and  estimating distance in real-time. OpenCV handles video capture and image processing. A  navigation script processes object data to move the vehicle autonomously toward a predefined  location. Upon arrival, Zoomie triggers a microphone to capture ambient speech. Whisper is used  to transcribe the audio into text. This text is then summarized using HuggingFace‚Äôs transformer- based summarizer and served to a backend API. A React app fetches the processed summaries  and displays them to the user.\n",
      "--------------------------------------------------\n",
      "[Section 10]\n",
      "Key Components: Input: Live camera feed and real-world audio at destination; Processing: Object  detection with YOLO, transcription using Whisper, summarization using transformers; Output:  Audio summary accessible via the React web app\n",
      "--------------------------------------------------\n",
      "[Section 11]\n",
      "Implementation Details: The vehicle is powered by a Raspberry Pi 4 running Python scripts for  real-time object detection and autonomous movement. YOLO is used to estimate the location and  distance of obstacles. Once the vehicle detects arrival at the destination using positional logic, it  triggers a microphone input. The audio is processed by Whisper for transcription, and the result is  summarized using HuggingFace‚Äôs summarization pipeline. A lightweight Flask backend serves the  summaries to a React frontend. GPIO interfaces control the vehicle‚Äôs motors and movement  components.\n",
      "--------------------------------------------------\n",
      "[Section 12]\n",
      "Results: Zoomie successfully reached test destinations with efficient obstacle detection and  avoidance; Captured audio was transcribed accurately using Whisper; Summarized outputs were  relevant and concise, delivered successfully to the React interface; Demonstrated real-world  viability of voice-based information logging through autonomous navigation.\n",
      "--------------------------------------------------\n",
      "[Section 13]\n",
      "Learnings: Integrating real-time vision and language models on a Raspberry Pi requires  optimization for performance and memory; Accurate arrival detection and trigger logic are  essential for seamless audio activation; Summarization quality can vary based on the clarity of  recorded speech and ambient noise; Frontend-backend synchronization is crucial for displaying  summaries effectively in real time.\n",
      "--------------------------------------------------\n",
      "[Section 14]\n",
      "Future Scope: Implement GPS or SLAM for more precise navigation, Add support for multilingual  speech processing, Enable image or video capture at destination sites in addition to audio,  Upgrade UI to allow users to send live instructions or view vehicle telemetry\n",
      "--------------------------------------------------\n",
      "[Section 15]\n",
      "Linked Resources:   Model references: YOLOv5, Whisper, HuggingFace transformers  Frontend: React app interface\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "view_document(\"Zoomie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acdb3b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted 15 entries with document_name = 'cookbook'.\n"
     ]
    }
   ],
   "source": [
    "delete_entries_by_name(\"cookbook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "620a6f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Documents stored:\n",
      "‚Ä¢ Name: Zoomie | Type: Project\n"
     ]
    }
   ],
   "source": [
    "list_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52740458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleared 15 documents from the vector DB at './chroma_phi'.\n"
     ]
    }
   ],
   "source": [
    "clear_database()\n",
    "#list_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f2f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fff7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
